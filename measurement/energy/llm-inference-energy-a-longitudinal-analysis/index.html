
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="ML.ENERGY research & tech blog">
      
      
        <meta name="author" content="The ML.ENERGY Initiative">
      
      
        <link rel="canonical" href="https://ml.energy/blog/measurement/energy/llm-inference-energy-a-longitudinal-analysis/">
      
      
        <link rel="prev" href="../diagnosing-inference-energy-consumption-with-the-mlenergy-leaderboard-v30/">
      
      
      
        
      
      
        <link rel="alternate" type="application/rss+xml" title="RSS feed" href="../../../feed_rss_created.xml">
        <link rel="alternate" type="application/rss+xml" title="RSS feed of updated content" href="../../../feed_rss_updated.xml">
      
      <link rel="icon" href="../../../assets/img/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.2">
    
    
      
        <title>LLM Inference Energy: A Longitudinal Analysis - ML.ENERGY Blog</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/css/color.css">
    
      <link rel="stylesheet" href="../../../assets/css/custom.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-C013T57GV2"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-C013T57GV2",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-C013T57GV2",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
  
  
    
  
  <meta property="og:type" content="website" />
  <meta property="og:title" content="ML.ENERGY Blog - LLM Inference Energy: A Longitudinal Analysis" />
  <meta property="og:description" content="ML.ENERGY research & tech blog" />
  <meta property="og:url" content="https://ml.energy/blog/measurement/energy/llm-inference-energy-a-longitudinal-analysis/" />
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="ML.ENERGY Blog - LLM Inference Energy: A Longitudinal Analysis" />
  <meta name="twitter:description" content="ML.ENERGY research & tech blog" />
  <meta name="twitter:image" content="https://ml.energy/assets/img/og_image.png" />

  
<meta property="og:type" content="website" />
<meta property="og:title" content="LLM Inference Energy: A Longitudinal Analysis - ML.ENERGY Blog" />
<meta property="og:description" content="ML.ENERGY research & tech blog" />
<meta property="og:image" content="https://ml.energy/blog/assets/img/social/measurement/energy/llm-inference-energy-a-longitudinal-analysis.png" />
<meta property="og:image:type" content="image/png" />
<meta property="og:image:width" content="1200" />
<meta property="og:image:height" content="630" />
<meta property="og:url" content="https://ml.energy/blog/measurement/energy/llm-inference-energy-a-longitudinal-analysis/" />
<meta property="twitter:card" content="summary_large_image" />
<meta property="twitter:title" content="LLM Inference Energy: A Longitudinal Analysis - ML.ENERGY Blog" />
<meta property="twitter:description" content="ML.ENERGY research & tech blog" />
<meta property="twitter:image" content="https://ml.energy/blog/assets/img/social/measurement/energy/llm-inference-energy-a-longitudinal-analysis.png" />
</head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="ml.energy" data-md-color-accent="ml.energy">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#llm-inference-energy-a-longitudinal-analysis" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
        <aside class="md-banner">
          <div class="md-banner__inner md-grid md-typeset">
            
              <button class="md-banner__button md-icon" aria-label="Don't show this again">
                
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
              </button>
            
            
  We're sharing updates via <a href="https://buttondown.com/ml-energy">The ML.ENERGY Newsletter</a>!

          </div>
          
            <script>var el=document.querySelector("[data-md-component=announce]");if(el){var content=el.querySelector(".md-typeset");__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0)}</script>
          
        </aside>
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="ML.ENERGY Blog" class="md-header__button md-logo" aria-label="ML.ENERGY Blog" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M11 15H6l7-14v8h5l-7 14z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            ML.ENERGY Blog
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              LLM Inference Energy: A Longitudinal Analysis
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="ml.energy" data-md-color-accent="ml.energy"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M178.2-10.1c7.4-3.1 15.8-2.2 22.5 2.2l87.8 58.2 87.8-58.2c6.7-4.4 15.1-5.2 22.5-2.2S411.4-.5 413 7.3l20.9 103.2 103.2 20.9c7.8 1.6 14.4 7 17.4 14.3s2.2 15.8-2.2 22.5L494.1 256l58.2 87.8c4.4 6.7 5.2 15.1 2.2 22.5s-9.6 12.8-17.4 14.3l-103.3 20.8L413 504.7c-1.6 7.8-7 14.4-14.3 17.4s-15.8 2.2-22.5-2.2l-87.8-58.2-87.8 58.2c-6.7 4.4-15.1 5.2-22.5 2.2s-12.8-9.6-14.3-17.4L143 401.4 39.7 380.5c-7.8-1.6-14.4-7-17.4-14.3s-2.2-15.8 2.2-22.5L82.7 256l-58.2-87.8c-4.4-6.7-5.2-15.1-2.2-22.5s9.6-12.8 17.4-14.3L143 110.6 163.9 7.3c1.6-7.8 7-14.4 14.3-17.4M207.6 256a80.4 80.4 0 1 1 160.8 0 80.4 80.4 0 1 1-160.8 0m208.8 0a128.4 128.4 0 1 0-256.8 0 128.4 128.4 0 1 0 256.8 0"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="ml.energy" data-md-color-accent="ml.energy"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M239.3 48.7C132.2 57.2 48 146.8 48 256c0 114.9 93.1 208 208 208 33.3 0 64.7-7.8 92.6-21.7C245.2 418.9 168 326.5 168 216c0-65.8 27.4-125.1 71.3-167.3M0 256C0 114.6 114.6 0 256 0c19.4 0 38.4 2.2 56.7 6.3 9.9 2.2 17.3 10.5 18.5 20.5s-4 19.8-13.1 24.4C257.5 81.4 216 143.9 216 216c0 101.6 82.4 184 184 184 5 0 9.9-.2 14.8-.6 10.1-.8 19.6 4.8 23.8 14.1s2 20.1-5.3 27.1C387.3 484.8 324.8 512 256 512 114.6 512 0 397.4 0 256"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
                
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" hidden>
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="ML.ENERGY Blog" class="md-nav__button md-logo" aria-label="ML.ENERGY Blog" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M11 15H6l7-14v8h5l-7 14z"/></svg>

    </a>
    ML.ENERGY Blog
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
    
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ML.ENERGY Research and Tech Blog
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Archive
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Archive
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../archive/2026/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2026
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../archive/2025/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2025
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../archive/2023/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2023
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Categories
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Categories
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../category/energy/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    energy
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../category/measurement/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    measurement
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../category/research/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    research
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
                
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#the-case-of-llama-31" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Case of Llama 3.1
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Case of Llama 3.1">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#energy-reduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Energy Reduction
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#token-throughput" class="md-nav__link">
    <span class="md-ellipsis">
      
        Token Throughput
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#power" class="md-nav__link">
    <span class="md-ellipsis">
      
        Power
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#putting-it-together" class="md-nav__link">
    <span class="md-ellipsis">
      
        Putting It Together
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summing-up" class="md-nav__link">
    <span class="md-ellipsis">
      
        Summing Up
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
  <div class="md-content md-content--post" data-md-component="content">
    <div class="md-sidebar md-sidebar--post" data-md-component="sidebar" data-md-type="navigation">
      <div class="md-sidebar__scrollwrap">
        <div class="md-sidebar__inner md-post">
          <nav class="md-nav md-nav--primary">
            <div class="md-post__back">
              <div class="md-nav__title md-nav__container">
                <a href="../../.." class="md-nav__link">
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
                  <span class="md-ellipsis">
                    Back to index
                  </span>
                </a>
              </div>
            </div>
            
              <div class="md-post__authors md-typeset">
                
                  <div class="md-profile md-post__profile">
                    <span class="md-author md-author--long">
                      <img src="https://ml.energy/assets/img/members/jae-won.jpg" alt="Jae-Won Chung">
                    </span>
                    <span class="md-profile__description">
                      <strong>
                        
                          Jae-Won Chung
                        
                      </strong>
                      <br>
                      PhD Student
                    </span>
                  </div>
                
              </div>
            
            <ul class="md-post__meta md-nav__list">
              <li class="md-nav__item md-nav__item--section">
                <div class="md-post__title">
                  <span class="md-ellipsis">
                    Metadata
                  </span>
                </div>
                <nav class="md-nav">
                  <ul class="md-nav__list">
                    <li class="md-nav__item">
                      <div class="md-nav__link">
                        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 19H5V8h14m-3-7v2H8V1H6v2H5c-1.11 0-2 .89-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2h-1V1m-1 11h-5v5h5z"/></svg>
                        <time datetime="2026-02-09 00:00:00+00:00" class="md-ellipsis">February 9, 2026</time>
                      </div>
                    </li>
                    
                    
                      <li class="md-nav__item">
                        <div class="md-nav__link">
                          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9 3v15h3V3zm3 2 4 13 3-1-4-13zM5 5v13h3V5zM3 19v2h18v-2z"/></svg>
                          <span class="md-ellipsis">
                            in
                            
                              <a href="../../../category/measurement/">measurement</a>, 
                              <a href="../../../category/energy/">energy</a></span>
                        </div>
                      </li>
                    
                    
                  </ul>
                </nav>
              </li>
            </ul>
            
              <ul class="md-post__meta md-nav__list">
                <li class="md-nav__item md-nav__item--section">
                  <div class="md-post__title">
                    <span class="md-ellipsis">
                      Related links
                    </span>
                  </div>
                  <nav class="md-nav">
                    <ul class="md-nav__list">
                      
                        
                        
  
  
  
  
    <li class="md-nav__item">
      <a href="https://ml.energy/leaderboard" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    The ML.ENERGY Leaderboard
  

    
  </span>
  
  

      </a>
    </li>
  

                      
                        
                        
  
  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/ml-energy/benchmark" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    The ML.ENERGY Benchmark
  

    
  </span>
  
  

      </a>
    </li>
  

                      
                    </ul>
                  </nav>
                </li>
              </ul>
            
          </nav>
          
        </div>
      </div>
    </div>
    <article class="md-content__inner md-typeset">
      
        
  




<h1 id="llm-inference-energy-a-longitudinal-analysis">LLM Inference Energy: A Longitudinal Analysis</h1>
<p>The ML.ENERGY Leaderboard went from v2.0 (September 2024) to <a href="https://ml.energy/leaderboard">v3.0</a> (December 2025) with major changes: up-to-date models, hardware, software, and datasets.
The <a href="../diagnosing-inference-energy-consumption-with-the-mlenergy-leaderboard-v30/">v3.0 blog post</a> covered the details of the v3.0 results, but how to they compare to the times v2.0?
Are we making progress on energy efficiency?
In this short post, we would like to look at the impact of <strong>software optimizations</strong> on energy efficiency over time, using the Llama 3.1 family as a case study.</p>
<!-- more -->

<h2 id="the-case-of-llama-31">The Case of Llama 3.1</h2>
<h3 id="energy-reduction">Energy Reduction</h3>
<p>To reason about how the software stack affects energy, we fix the model and hardware: the Llama 3.1 family (8B, 70B, 405B) on H100 GPUs with the same number of GPUs.</p>
<figure>
<p><img alt="Energy comparison" src="../../../assets/llm-energy-over-time/llama-energy-per-token-light.svg#only-light" />
  <img alt="Energy comparison" src="../../../assets/llm-energy-over-time/llama-energy-per-token-dark.svg#only-dark" />
  </p>
<figcaption>Energy per output token vs. batch size for Llama 3.1 models on H100 GPUs. For 405B, V2 uses BF16 and V3 uses FP8.</figcaption>
</figure>
<p>The 8B and 70B models are exactly the same in V2 and V3.
For the 405B model, we added one more layer: V3 uses native FP8 quantization.</p>
<p>At small <abbr title="The number of requests running concurrently. For LLM and MLLMs with variable number of requests running over time, batch size means the maximum number of requests (`max_num_seqs`) configured for the server. For diffusion models, batch size is exactly the number of items (e.g., images, videos) being generated together.">batch sizes</abbr>, V3 uses substantially less energy per <abbr title="LLMs understand and generate text in units of &quot;tokens,&quot; which can be words or parts of words. It depends on the model, but a token is roughly 0.75 words on average.">token</abbr> than V2.
For instance, the 8B model on <abbr title="The number of requests running concurrently. For LLM and MLLMs with variable number of requests running over time, batch size means the maximum number of requests (`max_num_seqs`) configured for the server. For diffusion models, batch size is exactly the number of items (e.g., images, videos) being generated together.">batch size</abbr> 64 reduces energy per <abbr title="LLMs understand and generate text in units of &quot;tokens,&quot; which can be words or parts of words. It depends on the model, but a token is roughly 0.75 words on average.">token</abbr> by 41% (0.20 J to 0.12 J).
The 70B model shows consistent improvements across all <abbr title="The number of requests running concurrently. For LLM and MLLMs with variable number of requests running over time, batch size means the maximum number of requests (`max_num_seqs`) configured for the server. For diffusion models, batch size is exactly the number of items (e.g., images, videos) being generated together.">batch sizes</abbr>, with up to a 15% reduction.
Similarly, the 405B model (especially with FP8) shows up to a 39% energy reduction at a <abbr title="The number of requests running concurrently. For LLM and MLLMs with variable number of requests running over time, batch size means the maximum number of requests (`max_num_seqs`) configured for the server. For diffusion models, batch size is exactly the number of items (e.g., images, videos) being generated together.">batch size</abbr> of 256.
V2 or V3, the mathematical operations carried out by a small <abbr title="The number of requests running concurrently. For LLM and MLLMs with variable number of requests running over time, batch size means the maximum number of requests (`max_num_seqs`) configured for the server. For diffusion models, batch size is exactly the number of items (e.g., images, videos) being generated together.">batch size</abbr> are the same.
Energy reductions come from software optimizations in vLLM (0.5.4 in V2 vs. 0.11.1 in V3).
Notably, at small <abbr title="The number of requests running concurrently. For LLM and MLLMs with variable number of requests running over time, batch size means the maximum number of requests (`max_num_seqs`) configured for the server. For diffusion models, batch size is exactly the number of items (e.g., images, videos) being generated together.">batch sizes</abbr> where the latency of one iteration is low, <a href="../diagnosing-inference-energy-consumption-with-the-mlenergy-leaderboard-v30/#multimodal-llm">CPU-side overheads</a> may bottleneck execution and underutilize the GPU, increasing <a href="../diagnosing-inference-energy-consumption-with-the-mlenergy-leaderboard-v30/#static-power-wastage">static power wastage</a> and energy consumption.
Software optimizations like vLLM Asynchronous Scheduling can mitigate this significantly.</p>
<p>At larger <abbr title="The number of requests running concurrently. For LLM and MLLMs with variable number of requests running over time, batch size means the maximum number of requests (`max_num_seqs`) configured for the server. For diffusion models, batch size is exactly the number of items (e.g., images, videos) being generated together.">batch sizes</abbr>, the energy gap narrows.
This is likely as <abbr title="The number of requests running concurrently. For LLM and MLLMs with variable number of requests running over time, batch size means the maximum number of requests (`max_num_seqs`) configured for the server. For diffusion models, batch size is exactly the number of items (e.g., images, videos) being generated together.">batch size</abbr> increases, the GPU becomes more fully utilized (with the same computations), and constant software-level loverheads are less significant relative to GPU computations.</p>
<p>To understand things deeper, let's break down energy per <abbr title="LLMs understand and generate text in units of &quot;tokens,&quot; which can be words or parts of words. It depends on the model, but a token is roughly 0.75 words on average.">token</abbr> into its components:</p>
<div class="arithmatex">\[
\frac{\text{Energy}}{\text{Token}}
= \frac{\text{Power} \cdot \text{Time}}{\text{Token}}
= \frac{\text{Power}}{\text{Token Throughput}}
\]</div>
<p>Let's look at each of these components.</p>
<h3 id="token-throughput">Token Throughput</h3>
<figure>
<p><img alt="Throughput comparison" src="../../../assets/llm-energy-over-time/llama-throughput-light.svg#only-light" />
  <img alt="Throughput comparison" src="../../../assets/llm-energy-over-time/llama-throughput-dark.svg#only-dark" />
  </p>
<figcaption>Token throughput vs. batch size for Llama 3.1 models on H100 GPUs.</figcaption>
</figure>
<p>At matched <abbr title="The number of requests running concurrently. For LLM and MLLMs with variable number of requests running over time, batch size means the maximum number of requests (`max_num_seqs`) configured for the server. For diffusion models, batch size is exactly the number of items (e.g., images, videos) being generated together.">batch sizes</abbr>, <strong>V3 achieves 3-5x higher throughput</strong> across all three model sizes.
Progress in software optimizations (especially vLLM) over more than a year is the main driver of this improvement.
V2's throughput curve is notably flat across <abbr title="The number of requests running concurrently. For LLM and MLLMs with variable number of requests running over time, batch size means the maximum number of requests (`max_num_seqs`) configured for the server. For diffusion models, batch size is exactly the number of items (e.g., images, videos) being generated together.">batch sizes</abbr>, suggesting the older vLLM version was unable to fully exploit increased parallelism from larger batches.
V3 shows the expected pattern: throughput climbs steeply with <abbr title="The number of requests running concurrently. For LLM and MLLMs with variable number of requests running over time, batch size means the maximum number of requests (`max_num_seqs`) configured for the server. For diffusion models, batch size is exactly the number of items (e.g., images, videos) being generated together.">batch size</abbr> and eventually saturates as GPU compute and memory bandwidth become the bottleneck.</p>
<p>With 3-5x throughput gains, one might expect proportional energy reductions.
But as we saw, energy per <abbr title="LLMs understand and generate text in units of &quot;tokens,&quot; which can be words or parts of words. It depends on the model, but a token is roughly 0.75 words on average.">token</abbr> improved only 15-41%.
Something is offsetting the throughput gains.</p>
<h3 id="power">Power</h3>
<figure>
<p><img alt="Power comparison" src="../../../assets/llm-energy-over-time/llama-power-light.svg#only-light" />
  <img alt="Power comparison" src="../../../assets/llm-energy-over-time/llama-power-dark.svg#only-dark" />
  </p>
<figcaption>Average GPU power vs. batch size for Llama 3.1 models on H100 GPUs.</figcaption>
</figure>
<p>vLLM GPU power draw is substantially higher in V3 than in V2.
Power draw is a good indicator of the GPU's utilization as it reflect hardware circuit activity directly, which is the core factor that drove throughput improvements.<sup id="fnref:v2-power"><a class="footnote-ref" href="#fn:v2-power">1</a></sup></p>
<h3 id="putting-it-together">Putting It Together</h3>
<p>V3's vLLM improvements keep the GPU busier, which both increases throughput (more <abbr title="LLMs understand and generate text in units of &quot;tokens,&quot; which can be words or parts of words. It depends on the model, but a token is roughly 0.75 words on average.">tokens</abbr> per second) and increases power draw (more of the GPU's circuitry is active).
Since energy per <abbr title="LLMs understand and generate text in units of &quot;tokens,&quot; which can be words or parts of words. It depends on the model, but a token is roughly 0.75 words on average.">token</abbr> is the ratio of these two quantities, the energy improvement depends on which one grows faster.
Throughput grew faster than power, resulting in a net energy reduction.</p>
<div class="admonition takeaway">
<p class="admonition-title">Takeaway</p>
<p>V3 achieves 3-5x higher throughput and 15-41% lower energy per <abbr title="LLMs understand and generate text in units of &quot;tokens,&quot; which can be words or parts of words. It depends on the model, but a token is roughly 0.75 words on average.">token</abbr> on Llama 3.1 models with the same hardware.
Especially, at small <abbr title="The number of requests running concurrently. For LLM and MLLMs with variable number of requests running over time, batch size means the maximum number of requests (`max_num_seqs`) configured for the server. For diffusion models, batch size is exactly the number of items (e.g., images, videos) being generated together.">batch sizes</abbr>, we see nearly a halving of energy per <abbr title="LLMs understand and generate text in units of &quot;tokens,&quot; which can be words or parts of words. It depends on the model, but a token is roughly 0.75 words on average.">token</abbr>, which is a significant improvement for latency-sensitive applications.
The reason energy per <abbr title="LLMs understand and generate text in units of &quot;tokens,&quot; which can be words or parts of words. It depends on the model, but a token is roughly 0.75 words on average.">token</abbr> improves less than throughput is that power also increases as the GPU is more fully utilized.</p>
</div>
<h2 id="summing-up">Summing Up</h2>
<p>Energy consumption is a pressing issue across the AI stack, from individual inference requests to datacenter-scale deployments.
But the V2-to-V3 transition shows that we are making relentless progress: software optimizations (vLLM 0.5.4 to 0.11.1) delivered 3-5x throughput improvements and measurable energy reductions.</p>
<p>The small <abbr title="The number of requests running concurrently. For LLM and MLLMs with variable number of requests running over time, batch size means the maximum number of requests (`max_num_seqs`) configured for the server. For diffusion models, batch size is exactly the number of items (e.g., images, videos) being generated together.">batch size</abbr> (i.e., low latency) regime is the most challenging to run efficiently, and as we saw, that is also where software optimizations had the biggest impact on energy efficiency.
This regime actually matters a lot for <em>agentic</em> applications that generate a <em>ton</em> of <abbr title="LLMs understand and generate text in units of &quot;tokens,&quot; which can be words or parts of words. It depends on the model, but a token is roughly 0.75 words on average.">tokens</abbr>; in order to keep latency in a reasonable range, these applications often run with small <abbr title="The number of requests running concurrently. For LLM and MLLMs with variable number of requests running over time, batch size means the maximum number of requests (`max_num_seqs`) configured for the server. For diffusion models, batch size is exactly the number of items (e.g., images, videos) being generated together.">batch sizes</abbr>.
In this specific analysis, we see nearly a halving of energy per <abbr title="LLMs understand and generate text in units of &quot;tokens,&quot; which can be words or parts of words. It depends on the model, but a token is roughly 0.75 words on average.">token</abbr> at smaller <abbr title="The number of requests running concurrently. For LLM and MLLMs with variable number of requests running over time, batch size means the maximum number of requests (`max_num_seqs`) configured for the server. For diffusion models, batch size is exactly the number of items (e.g., images, videos) being generated together.">batch sizes</abbr>, which is a significant improvement for these applications.</p>
<p>Progress spans the entire stack (inference engines, model architectures, quantization, and hardware) and the improvements compound.
To understand how all these factors interact and to learn how to reason about and explain energy consumption, see <a href="../diagnosing-inference-energy-consumption-with-the-mlenergy-leaderboard-v30/">our V3 leaderboard blog post</a>.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:v2-power">
<p>Full disclosure: V2 only measured power during the entire benchmark duration (not explicitly during the steady-state window), which underestimates V2's power draw. This gets worse at larger <abbr title="The number of requests running concurrently. For LLM and MLLMs with variable number of requests running over time, batch size means the maximum number of requests (`max_num_seqs`) configured for the server. For diffusion models, batch size is exactly the number of items (e.g., images, videos) being generated together.">batch sizes</abbr>, where the relative duration of the steady state takes up a shorter portion of the entire duration. However, even with some underestimation of V2's power, the gap is large enough to conclude that vLLM draws more power in V3 than in V2.&#160;<a class="footnote-backref" href="#fnref:v2-power" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>







  
  



  


  



      
    </article>
  </div>

          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
<div class="newsletter-signup">
  <div class="newsletter-content">
    <h3>Stay Updated</h3>
    <p>Subscribe to our newsletter for the latest ML energy research.</p>
    <form
      action="https://buttondown.com/api/emails/embed-subscribe/ml-energy"
      method="post"
      class="newsletter-form"
    >
      <input type="email" name="email" placeholder="Enter your email" required />
      <button type="submit">Subscribe</button>
    </form>
  </div>
</div>

        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023-2026 The ML.ENERGY Initiative
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://ml.energy/blog/feed_rss_created.xml" target="_blank" rel="noopener" title="ml.energy" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.18 15.64a2.18 2.18 0 0 1 2.18 2.18C8.36 19 7.38 20 6.18 20 5 20 4 19 4 17.82a2.18 2.18 0 0 1 2.18-2.18M4 4.44A15.56 15.56 0 0 1 19.56 20h-2.83A12.73 12.73 0 0 0 4 7.27zm0 5.66a9.9 9.9 0 0 1 9.9 9.9h-2.83A7.07 7.07 0 0 0 4 12.93z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      

    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["search.suggest", "navigation.sections", "navigation.instant", "navigation.instant.prefetch", "content.tooltips", "content.code.copy", "announce.dismiss"], "search": "../../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../../assets/js/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>