<?xml version="1.0" encoding="UTF-8" ?> <rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"> <channel> <title>ML.ENERGY Blog</title><description>ML.ENERGY research &amp; tech blog</description><link>https://ml.energy/blog/</link><atom:link href="https://ml.energy/blog/feed_rss_updated.xml" rel="self" type="application/rss+xml" /> <managingEditor>The ML.ENERGY Initiative</managingEditor><language>en</language> <pubDate>Wed, 18 Feb 2026 18:02:11 -0000</pubDate> <lastBuildDate>Wed, 18 Feb 2026 18:02:11 -0000</lastBuildDate> <ttl>1440</ttl> <generator>MkDocs RSS plugin - v1.17.9</generator> <image> <url>None</url> <title>ML.ENERGY Blog</title> <link>https://ml.energy/blog/</link> </image> <item> <title>Measuring GPU Energy: Best Practices</title> <author>Jae-Won Chung</author> <category>energy</category> <category>measurement</category> <description>&lt;h1&gt;Measuring GPU Energy: Best Practices&lt;/h1&gt; &lt;p&gt;To optimize something, you need to be able to measure it right. In this post, we&#39;ll look into potential pitfalls and best practices for GPU energy measurement.&lt;/p&gt;</description> <link>https://ml.energy/blog/energy/measurement/measuring-gpu-energy-best-practices/</link> <pubDate>Wed, 18 Feb 2026 18:01:46 +0000</pubDate> <source url="https://ml.energy/blog/feed_rss_updated.xml">ML.ENERGY Blog</source><guid isPermaLink="true">https://ml.energy/blog/energy/measurement/measuring-gpu-energy-best-practices/</guid> <enclosure url="https://ml.energy/blog/assets/img/social/energy/measurement/measuring-gpu-energy-best-practices.png" type="image/png" length="46717" /> </item> <item> <title>ML Energy, Performance, and Accuracy</title> <author>Jae-Won Chung</author> <category>energy</category> <category>research</category> <description>&lt;h1&gt;ML Energy, Performance, and Accuracy&lt;/h1&gt; &lt;p&gt;Zeus&#39;s &lt;a href=&#34;https://ml.energy/zeus/optimize/batch_size_optimizer&#34;&gt;batch size optimizer&lt;/a&gt; changes the model&#39;s training batch size to optimize time and energy consumption, but does that hurt the model&#39;s final quality? Short answer: No. Let&#39;s look into how in today&#39;s post.&lt;/p&gt;</description> <link>https://ml.energy/blog/energy/research/ml-energy-performance-and-accuracy/</link> <pubDate>Wed, 18 Feb 2026 18:01:46 +0000</pubDate> <source url="https://ml.energy/blog/feed_rss_updated.xml">ML.ENERGY Blog</source><guid isPermaLink="true">https://ml.energy/blog/energy/research/ml-energy-performance-and-accuracy/</guid> <enclosure url="https://ml.energy/blog/assets/img/social/energy/research/ml-energy-performance-and-accuracy.png" type="image/png" length="41326" /> </item> <item> <title>LLM Inference Energy: A Longitudinal Analysis</title> <author>Jae-Won Chung</author> <category>energy</category> <category>measurement</category> <description>&lt;h1&gt;LLM Inference Energy: A Longitudinal Analysis&lt;/h1&gt; &lt;p&gt;The ML.ENERGY Leaderboard went from v2.0 (September 2024) to &lt;a href=&#34;https://ml.energy/leaderboard&#34;&gt;v3.0&lt;/a&gt; (December 2025) with major changes: up-to-date models, hardware, software, and datasets. The &lt;a href=&#34;ml-energy-leaderboard-v3.0.md&#34;&gt;v3.0 blog post&lt;/a&gt; covered the details of the v3.0 results, but how to they compare to the times v2.0? Are we making progress on energy efficiency? In this short post, we would like to look at the impact of &lt;strong&gt;software optimizations&lt;/strong&gt; on energy efficiency over time, using the Llama 3.1 family as a case study.&lt;/p&gt;</description> <link>https://ml.energy/blog/measurement/energy/llm-inference-energy-a-longitudinal-analysis/</link> <pubDate>Wed, 18 Feb 2026 18:01:46 +0000</pubDate> <source url="https://ml.energy/blog/feed_rss_updated.xml">ML.ENERGY Blog</source><guid isPermaLink="true">https://ml.energy/blog/measurement/energy/llm-inference-energy-a-longitudinal-analysis/</guid> <enclosure url="https://ml.energy/blog/assets/img/social/measurement/energy/llm-inference-energy-a-longitudinal-analysis.png" type="image/png" length="38544" /> </item> <item> <title>Diagnosing Inference Energy Consumption with the ML.ENERGY Leaderboard v3.0</title> <author>Jae-Won Chung</author> <category>energy</category> <category>measurement</category> <description>&lt;h1&gt;Diagnosing Inference Energy Consumption with the ML.ENERGY Leaderboard v3.0&lt;/h1&gt; &lt;p&gt;With &lt;a href=&#34;https://github.com/ml-energy/benchmark/releases/tag/v3.0&#34;&gt;The ML.ENERGY Benchmark v3.0&lt;/a&gt; we released in December 2025, we expanded our scope to up-to-date important models, tasks, and GPU hardware. This included 46 models across 7 tasks, producing 1,858 configurations on NVIDIA H100 and B200 GPUs.[^software-setup] As always, latest benchmarking results are public and can be browsed on &lt;a href=&#34;https://ml.energy/leaderboard&#34;&gt;The ML.ENERGY Leaderboard&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;In this post, we first present empirical observations from measurements, and then develop a reasoning framework that explains &lt;em&gt;why&lt;/em&gt; we observe certain energy behaviors.&lt;/p&gt;</description> <link>https://ml.energy/blog/measurement/energy/diagnosing-inference-energy-consumption-with-the-mlenergy-leaderboard-v30/</link> <pubDate>Wed, 18 Feb 2026 18:01:46 +0000</pubDate> <source url="https://ml.energy/blog/feed_rss_updated.xml">ML.ENERGY Blog</source><guid isPermaLink="true">https://ml.energy/blog/measurement/energy/diagnosing-inference-energy-consumption-with-the-mlenergy-leaderboard-v30/</guid> <enclosure url="https://ml.energy/blog/assets/img/social/measurement/energy/diagnosing-inference-energy-consumption-with-the-mlenergy-leaderboard-v30.png" type="image/png" length="44658" /> </item> <item> <title>Profiling LLM energy consumption on Macs</title> <author>Jisang (Michael) Ahn</author> <author>Jae-Won Chung</author> <category>energy</category> <category>measurement</category> <description>&lt;h1&gt;Profiling LLM energy consumption on Macs&lt;/h1&gt; &lt;p&gt;If you want to see how much energy LLM inference consumes on Apple Silicon, it&#39;s hard to find a straightforward way to do this programmatically, from within code. In this post, we&#39;ll explore how we can do this.&lt;/p&gt;</description> <link>https://ml.energy/blog/energy/measurement/profiling-llm-energy-consumption-on-macs/</link> <pubDate>Wed, 18 Feb 2026 18:01:46 +0000</pubDate> <source url="https://ml.energy/blog/feed_rss_updated.xml">ML.ENERGY Blog</source><guid isPermaLink="true">https://ml.energy/blog/energy/measurement/profiling-llm-energy-consumption-on-macs/</guid> <enclosure url="https://ml.energy/blog/assets/img/social/energy/measurement/profiling-llm-energy-consumption-on-macs.png" type="image/png" length="42199" /> </item> </channel> </rss>